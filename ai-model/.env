PERSIST_DIRECTORY=DB
SOURCE_DIRECTORY=uploads
MODEL_TYPE=GPT4All
MODEL_PATH=D:\intellidoc\models\llama-2-7b-chat.ggmlv3.q5_K_S.bin
EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2
MODEL_N_CTX=1000
MODEL_N_BATCH=8
TARGET_SOURCE_CHUNKS=4
# PATH=C:\Program Files\CMake\bin
# CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.83 --no-cache-dir
